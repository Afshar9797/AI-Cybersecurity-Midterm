{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI&Cyber Security.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgCnbNz82l5u",
        "colab_type": "text"
      },
      "source": [
        "##                         **CLOUD-BASED PE MALWARE DETECTION API**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGdS9Elzb03F",
        "colab_type": "code",
        "outputId": "ad1d79d2-d548-4aa9-de6e-0ead8667be09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!wget https://pubdata.endgame.com/ember/ember_dataset_2017_2.tar.bz2 --no-check-certificate"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-16 00:03:04--  https://pubdata.endgame.com/ember/ember_dataset_2017_2.tar.bz2\n",
            "Resolving pubdata.endgame.com (pubdata.endgame.com)... 64.250.189.21\n",
            "Connecting to pubdata.endgame.com (pubdata.endgame.com)|64.250.189.21|:443... connected.\n",
            "WARNING: cannot verify pubdata.endgame.com's certificate, issued by ‘CN=Go Daddy Secure Certificate Authority - G2,OU=http://certs.godaddy.com/repository/,O=GoDaddy.com\\\\, Inc.,L=Scottsdale,ST=Arizona,C=US’:\n",
            "  Issued certificate has expired.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1751237573 (1.6G) [application/octet-stream]\n",
            "Saving to: ‘ember_dataset_2017_2.tar.bz2’\n",
            "\n",
            "ember_dataset_2017_ 100%[===================>]   1.63G  13.7MB/s    in 61s     \n",
            "\n",
            "2020-04-16 00:04:05 (27.3 MB/s) - ‘ember_dataset_2017_2.tar.bz2’ saved [1751237573/1751237573]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JK-41RkMdFdA",
        "colab_type": "code",
        "outputId": "8792e6fd-75f7-4351-e628-e709dc8925fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!tar -xvf ember_dataset_2017_2.tar.bz2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ember_2017_2/\n",
            "ember_2017_2/train_features_1.jsonl\n",
            "ember_2017_2/train_features_0.jsonl\n",
            "ember_2017_2/train_features_3.jsonl\n",
            "ember_2017_2/test_features.jsonl\n",
            "ember_2017_2/train_features_5.jsonl\n",
            "ember_2017_2/train_features_4.jsonl\n",
            "ember_2017_2/train_features_2.jsonl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdxJy-K8eEEV",
        "colab_type": "code",
        "outputId": "e806d7bc-48e4-4909-ca7a-76a55795a36d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "!wget https://github.com/endgameinc/ember/archive/master.zip\n",
        "!unzip master.zip\n",
        "!rm master.zip\n",
        "!cp -r ember-master/* .\n",
        "!rm -r ember-master"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-15 01:45:07--  https://github.com/endgameinc/ember/archive/master.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/endgameinc/ember/zip/master [following]\n",
            "--2020-04-15 01:45:07--  https://codeload.github.com/endgameinc/ember/zip/master\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.9\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [      <=>           ]  11.22M  4.90MB/s    in 2.3s    \n",
            "\n",
            "2020-04-15 01:45:11 (4.90 MB/s) - ‘master.zip’ saved [11769324]\n",
            "\n",
            "Archive:  master.zip\n",
            "f9a018632ba108b4e25c33d6c3e2e7a7c4487f58\n",
            "   creating: ember-master/\n",
            "  inflating: ember-master/LICENSE.txt  \n",
            "  inflating: ember-master/README.md  \n",
            "   creating: ember-master/ember/\n",
            "  inflating: ember-master/ember/__init__.py  \n",
            "  inflating: ember-master/ember/features.py  \n",
            "   creating: ember-master/licenses/\n",
            "  inflating: ember-master/licenses/AGPL-LICENSE-3.0.txt  \n",
            "  inflating: ember-master/licenses/MIT-LICENSE.txt  \n",
            "   creating: ember-master/malconv/\n",
            "  inflating: ember-master/malconv/README.md  \n",
            "  inflating: ember-master/malconv/malconv.h5  \n",
            "  inflating: ember-master/malconv/malconv.py  \n",
            "  inflating: ember-master/malconv/multi_gpu.py  \n",
            "  inflating: ember-master/requirements.txt  \n",
            "  inflating: ember-master/requirements_conda.txt  \n",
            "  inflating: ember-master/requirements_notebook.txt  \n",
            "   creating: ember-master/resources/\n",
            "  inflating: ember-master/resources/ember-notebook.ipynb  \n",
            "  inflating: ember-master/resources/ember2018-notebook.ipynb  \n",
            "  inflating: ember-master/resources/logo.png  \n",
            "   creating: ember-master/scripts/\n",
            "  inflating: ember-master/scripts/classify_binaries.py  \n",
            "  inflating: ember-master/scripts/train_ember.py  \n",
            "  inflating: ember-master/setup.py   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFYVFovqgtz-",
        "colab_type": "code",
        "outputId": "7d63db79-cdea-4472-ac3a-bd4b0a56b889",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -r requirements.txt\n",
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lief>=0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/38/e6bf942cf2ee073bf81fa3324bca35409175312b7b72d71919c8fc8e547b/lief-0.10.1-cp36-cp36m-manylinux1_x86_64.whl (3.5MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.31.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (4.38.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.18.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.0.3)\n",
            "Requirement already satisfied: lightgbm>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (2.2.3)\n",
            "Requirement already satisfied: scikit-learn>=0.20.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (0.22.2.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->-r requirements.txt (line 4)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->-r requirements.txt (line 4)) (2018.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm>=2.2.3->-r requirements.txt (line 5)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.3->-r requirements.txt (line 6)) (0.14.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.24.2->-r requirements.txt (line 4)) (1.12.0)\n",
            "Installing collected packages: lief\n",
            "Successfully installed lief-0.10.1\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating ember.egg-info\n",
            "writing ember.egg-info/PKG-INFO\n",
            "writing dependency_links to ember.egg-info/dependency_links.txt\n",
            "writing requirements to ember.egg-info/requires.txt\n",
            "writing top-level names to ember.egg-info/top_level.txt\n",
            "writing manifest file 'ember.egg-info/SOURCES.txt'\n",
            "reading manifest file 'ember.egg-info/SOURCES.txt'\n",
            "writing manifest file 'ember.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/ember\n",
            "copying ember/features.py -> build/lib/ember\n",
            "copying ember/__init__.py -> build/lib/ember\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/ember\n",
            "copying build/lib/ember/features.py -> build/bdist.linux-x86_64/egg/ember\n",
            "copying build/lib/ember/__init__.py -> build/bdist.linux-x86_64/egg/ember\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ember/features.py to features.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/ember/__init__.py to __init__.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying ember.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/ember-0.1.0-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing ember-0.1.0-py3.6.egg\n",
            "Copying ember-0.1.0-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding ember 0.1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/ember-0.1.0-py3.6.egg\n",
            "Processing dependencies for ember==0.1.0\n",
            "Searching for scikit-learn==0.22.2.post1\n",
            "Best match: scikit-learn 0.22.2.post1\n",
            "Adding scikit-learn 0.22.2.post1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for lightgbm==2.2.3\n",
            "Best match: lightgbm 2.2.3\n",
            "Adding lightgbm 2.2.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pandas==1.0.3\n",
            "Best match: pandas 1.0.3\n",
            "Adding pandas 1.0.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.18.2\n",
            "Best match: numpy 1.18.2\n",
            "Adding numpy 1.18.2 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for tqdm==4.38.0\n",
            "Best match: tqdm 4.38.0\n",
            "Adding tqdm 4.38.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for lief==0.10.1\n",
            "Best match: lief 0.10.1\n",
            "Adding lief 0.10.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for joblib==0.14.1\n",
            "Best match: joblib 0.14.1\n",
            "Adding joblib 0.14.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pytz==2018.9\n",
            "Best match: pytz 2018.9\n",
            "Adding pytz 2018.9 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-dateutil==2.8.1\n",
            "Best match: python-dateutil 2.8.1\n",
            "Adding python-dateutil 2.8.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for ember==0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdZXJ4e_3Knn",
        "colab_type": "text"
      },
      "source": [
        "#vectorizing Sample Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcT-IsCehFEv",
        "colab_type": "code",
        "outputId": "ea191550-7c8c-46b6-a5a6-d95ab15e6d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "import ember\n",
        "ember.create_vectorized_features(\"ember_2017_2/\")\n",
        "ember.create_metadata(\"ember_2017_2/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.10.1-bfe5414 found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n",
            "Vectorizing training set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 900000/900000 [31:17<00:00, 479.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Vectorizing test set\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 200000/200000 [06:54<00:00, 482.77it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sha256</th>\n",
              "      <th>appeared</th>\n",
              "      <th>subset</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...</td>\n",
              "      <td>2006-12</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d4206650743b3d519106dea10a38a55c30467c3d9f7875...</td>\n",
              "      <td>2006-12</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...</td>\n",
              "      <td>2007-01</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7f513818bcc276c531af2e641c597744da807e21cc1160...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...</td>\n",
              "      <td>2007-02</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099995</th>\n",
              "      <td>fffe314f23cee3a68ccab272934877d3bc18ec3bd905df...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099996</th>\n",
              "      <td>fffe7a1b23e04facc9ca91a93ac4a34e8b3040e023dbde...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099997</th>\n",
              "      <td>fffe801f51e7ec931515aa49a3d157a9c0fbcdca8c9d80...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099998</th>\n",
              "      <td>fffe92f9593649c4a7050302368189de45e2c1c06b04ea...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1099999</th>\n",
              "      <td>ffffb259a4c5e25ae1437af59caafb718cf8879187cc8c...</td>\n",
              "      <td>2017-12</td>\n",
              "      <td>test</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1100000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    sha256  ... label\n",
              "0        0abb4fda7d5b13801d63bee53e5e256be43e141faa077a...  ...     0\n",
              "1        d4206650743b3d519106dea10a38a55c30467c3d9f7875...  ...     0\n",
              "2        c9cafff8a596ba8a80bafb4ba8ae6f2ef3329d95b85f15...  ...     0\n",
              "3        7f513818bcc276c531af2e641c597744da807e21cc1160...  ...     0\n",
              "4        ca65e1c387a4cc9e7d8a8ce12bf1bcf9f534c9032b9d95...  ...     0\n",
              "...                                                    ...  ...   ...\n",
              "1099995  fffe314f23cee3a68ccab272934877d3bc18ec3bd905df...  ...     0\n",
              "1099996  fffe7a1b23e04facc9ca91a93ac4a34e8b3040e023dbde...  ...     1\n",
              "1099997  fffe801f51e7ec931515aa49a3d157a9c0fbcdca8c9d80...  ...     0\n",
              "1099998  fffe92f9593649c4a7050302368189de45e2c1c06b04ea...  ...     1\n",
              "1099999  ffffb259a4c5e25ae1437af59caafb718cf8879187cc8c...  ...     1\n",
              "\n",
              "[1100000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fB85K9PjbGLv",
        "colab_type": "text"
      },
      "source": [
        "#Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhMxuxiSsAY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  import tensorflow as tf\n",
        "  from tensorflow import keras\n",
        "  from tensorflow.keras import layers\n",
        "  feature_size=2381\n",
        "  tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "  keras.backend.clear_session()\n",
        "  \n",
        "  #Model architecture\n",
        "  from tensorflow.keras import layers\n",
        "  \n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(layers.InputLayer(input_shape=(1,feature_size)))\n",
        "  model.add(layers.Dropout(0.2))\n",
        "  model.add(layers.Dense(1000, activation='relu'))\n",
        "  model.add(layers.Dense(1800, activation='relu'))\n",
        "  model.add(layers.Dense(2000, activation='relu'))\n",
        "\n",
        "\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "  model.compile(tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz4Brs67M-7l",
        "colab_type": "code",
        "outputId": "d43a2544-1d5b-4cbe-eb91-4b158ac6eff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dropout (Dropout)            (None, 1, 2381)           0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1, 1000)           2382000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1, 1000)           0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1, 1)              1001      \n",
            "=================================================================\n",
            "Total params: 2,383,001\n",
            "Trainable params: 2,383,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEW4P5MrshF_",
        "colab_type": "code",
        "outputId": "8bcac89d-01cd-4a3b-befb-0fcf6a441717",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "import ember\n",
        "X_train, y_train, X_test, y_test = ember.read_vectorized_features(\"ember_2017_2/\")\n",
        "metadata_dataframe = ember.read_metadata(\"ember_2017_2/\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: EMBER feature version 2 were computed using lief version 0.9.0-\n",
            "WARNING:   lief version 0.10.1-bfe5414 found instead. There may be slight inconsistencies\n",
            "WARNING:   in the feature calculations.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvD9BMnks1_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelrows = (y_train != -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmUupi-eWcC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train[labelrows]\n",
        "y_train = y_train[labelrows]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_SjGz1LWf6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Standardizing the training data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "std = StandardScaler()\n",
        "\n",
        "for x in range(0,700000,100000):\n",
        "  std.partial_fit(X_train[x:x+100000])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TmW9erfE0rn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = std.fit_transform(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7btdMDaZ3sRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshaping the training data\n",
        "import numpy as np\n",
        "X_train = np.reshape(X_train,(-1,1,2381))\n",
        "y_train = np.reshape(y_train,(-1,1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnp7Wwcdbyws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Standardizing the testing data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "mms = StandardScaler()\n",
        "\n",
        "X_test = mms.fit_transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIKWwt1WOyCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = std.fit_transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MapV1yNPJyVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshaping the testing data\n",
        "import numpy as np\n",
        "X_test = np.reshape(X_test,(-1,1,2381))\n",
        "y_test = np.reshape(y_test,(-1,1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QewE2-ZDd-D8",
        "colab_type": "text"
      },
      "source": [
        "#Model Training and Evaluating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBbRkUHVNrR4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP9-Cx4WNrkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "          loss='binary_crossentropy',\n",
        "          metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Precision()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUEP0ZmUm02B",
        "colab_type": "code",
        "outputId": "0c23a331-71f8-4ad3-ac46-5b227a01ea41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                batch_size=315,\n",
        "                epochs=1,\n",
        "                  validation_data =((X_test,y_test))\n",
        "                  )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 700000 samples, validate on 200000 samples\n",
            "700000/700000 [==============================] - 179s 298us/sample - loss: 4.2120 - accuracy: 0.9646 - val_loss: 3.3853 - val_accuracy: 0.9303\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwL1EMg4NWLd",
        "colab_type": "text"
      },
      "source": [
        "#prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypyKPx5qI7xP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction= model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrW7NB1jU3Ls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = np.reshape(y_test,(-1))\n",
        "prediction = np.reshape(prediction,(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSLJ77z5VWI1",
        "colab_type": "code",
        "outputId": "d3cf6696-8ff9-4a0e-e22d-028476c4d8eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([1., 1., 0., ..., 0., 1., 1.], dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BWnF6cJVtxJ",
        "colab_type": "code",
        "outputId": "d9a7a9ba-7bee-4375-a775-a5edab75b8c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "prediction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([1., 1., 0., ..., 0., 1., 1.], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L-uUKShNbYQ",
        "colab_type": "text"
      },
      "source": [
        "#F1 Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx6-oZaYV5pI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "score = f1_score(y_test_int, pred_int) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjh_HMhAWL7o",
        "colab_type": "code",
        "outputId": "86e3d08f-81a9-42c6-ac85-7471ce722138",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9367284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMWbSUetNfxN",
        "colab_type": "text"
      },
      "source": [
        "#Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUjadK1tXdUb",
        "colab_type": "code",
        "outputId": "3966251e-77e2-4673-b817-6f9918b3f99b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "precision = sklearn.metrics.precision_score(y_test_int,pred_int)\n",
        "precision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.963842"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3fWlokJYWha",
        "colab_type": "code",
        "outputId": "8ac129a4-5974-4976-82b4-138c9d1adaf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "!wget https://the.earth.li/~sgtatham/putty/latest/w32/putty.exe   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-16 04:04:38--  https://the.earth.li/~sgtatham/putty/latest/w32/putty.exe\n",
            "Resolving the.earth.li (the.earth.li)... 93.93.131.124, 2a00:1098:86:4d:c0ff:ee:15:900d\n",
            "Connecting to the.earth.li (the.earth.li)|93.93.131.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://the.earth.li/~sgtatham/putty/0.73/w32/putty.exe [following]\n",
            "--2020-04-16 04:04:38--  https://the.earth.li/~sgtatham/putty/0.73/w32/putty.exe\n",
            "Reusing existing connection to the.earth.li:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1096080 (1.0M) [application/x-msdos-program]\n",
            "Saving to: ‘putty.exe.1’\n",
            "\n",
            "putty.exe.1         100%[===================>]   1.04M   520KB/s    in 2.1s    \n",
            "\n",
            "2020-04-16 04:04:40 (520 KB/s) - ‘putty.exe.1’ saved [1096080/1096080]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG3vvzK2LSgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "std_1 = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtYml346GNv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def testing(pefile):\n",
        "  try:\n",
        "    import ember\n",
        "  except:\n",
        "    !wget https://github.com/endgameinc/ember/archive/master.zip\n",
        "    !unzip master.zip\n",
        "    !rm master.zip\n",
        "    !cp -r ember-master/* .\n",
        "    !rm -r ember-master\n",
        "    !pip install -r requirements.txt\n",
        "    !python setup.py install\n",
        "    import ember\n",
        "\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  import tensorflow as tf\n",
        "  tf.compat.v1.disable_eager_execution()\n",
        "  data = open(pefile, \"rb\").read()\n",
        "  features = ember.PEFeatureExtractor(2)\n",
        "  data = np.array(extractor.feature_vector(data), dtype=np.float32)\n",
        "  data = std_1.transform([data])\n",
        "  data = np.reshape(data,(-1,1,2381))\n",
        "  prediction = model.predict_classes(data)\n",
        "\n",
        "  return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Nj-ZuThMwia",
        "colab_type": "code",
        "outputId": "63844eb6-77f3-4a3d-fcc0-f9ca28a2d0b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "testing(\"putty.exe\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-33-fd0bf5dddfde>:19: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "array([[[0]]], dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhq3almyK6ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}